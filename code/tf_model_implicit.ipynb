{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Build\n",
    "\n",
    "<font color='red'>NOTE</font>\n",
    " \n",
    "* Notebook based on [this](https://blog.paperspace.com/movie-recommender-tensorflow/) tutorial. \n",
    "* see also [context feature implementation](https://www.tensorflow.org/recommenders/examples/context_features) and the corresponding [youtube video](https://www.youtube.com/watch?v=RWlLaWMD30M&t=1s)\n",
    "\n",
    "* Recommender runs, however only one recommendation for a given user_id, don't know why. \n",
    "\n",
    "To do:\n",
    "* Implement context features to take advantage of all the given variables\n",
    "<br>--> if we are able to do this, we might have something that would be viable for production (apparently this query-model-thing with consideration of context is the real-world approach), that would help for answer of Question 1 and 2 of the project description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliviergisiger/.local/share/virtualenvs/deezer_recommendation-BCCDOVtY/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from numpy import count_nonzero\n",
    "\n",
    "from typing import Dict, Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/train.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b0/_hhr9zlj5wdd5ftyj21pr9vw0000gn/T/ipykernel_5972/40870951.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_listened_small[['user_id', 'media_id']] = train_listened_small[['user_id', 'media_id']].astype(str)\n"
     ]
    }
   ],
   "source": [
    "# filter for is listened == 1\n",
    "\n",
    "train_listened = train_df[train_df['is_listened'] == 1]\n",
    "train_listened.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# only first 100'000 records\n",
    "train_listened_small = train_listened.loc[:99999]\n",
    "train_listened_small[['user_id', 'media_id']] = train_listened_small[['user_id', 'media_id']].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "WARNING:tensorflow:From /Users/oliviergisiger/.local/share/virtualenvs/deezer_recommendation-BCCDOVtY/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "{'user_id': b'16547', 'is_listened': 1, 'media_id': b'250467', 'timestamp': 1480544735}\n",
      "{'user_id': b'7665', 'is_listened': 1, 'media_id': b'305197', 'timestamp': 1479563953}\n",
      "{'user_id': b'1812', 'is_listened': 1, 'media_id': b'542335', 'timestamp': 1478368974}\n",
      "{'user_id': b'1812', 'is_listened': 1, 'media_id': b'542335', 'timestamp': 1478382544}\n",
      "{'user_id': b'1812', 'is_listened': 1, 'media_id': b'542335', 'timestamp': 1478338409}\n",
      "<MapDataset element_spec={'user_id': TensorSpec(shape=(), dtype=tf.string, name=None), 'is_listened': TensorSpec(shape=(), dtype=tf.int64, name=None), 'media_id': TensorSpec(shape=(), dtype=tf.string, name=None), 'timestamp': TensorSpec(shape=(), dtype=tf.int64, name=None)}>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 17:34:20.660957: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-03-12 17:34:20.661003: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2023-03-12 17:34:20.742453: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "# convert to tfds datset\n",
    "\n",
    "deezer_ratings = tf.data.Dataset.from_tensor_slices(dict(train_listened_small)).\\\n",
    "    map(lambda x: {\n",
    "    'user_id': x['user_id'], \n",
    "    'is_listened': x['is_listened'], \n",
    "    'media_id': x['media_id'], \n",
    "    'timestamp': x['ts_listen']})\n",
    "\n",
    "# get sample for overview\n",
    "for x in deezer_ratings.take(5).as_numpy_iterator():\n",
    "    print(x)\n",
    "\n",
    "# assert correct object type\n",
    "print(deezer_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = deezer_ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(2_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data\n",
    "# for x in test.take(5).as_numpy_iterator():\n",
    "#   print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = deezer_ratings.map(lambda x: x[\"media_id\"])\n",
    "user = deezer_ratings.map(lambda x: x[\"user_id\"])\n",
    "\n",
    "song_ids = deezer_ratings.batch(1_000_000).map(lambda x: x[\"media_id\"])\n",
    "user_ids = deezer_ratings.batch(1_000_000).map(lambda x: x[\"user_id\"])\n",
    "\n",
    "unique_song_ids = np.unique(np.concatenate(list(song_ids)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))\n",
    "\n",
    "# context variable: unix timestamps\n",
    "# timestamps = np.concatenate(list(deezer_ratings.map(lambda x: x[\"timestamp\"]).batch(100)))\n",
    "# max_timestamp = timestamps.max()\n",
    "# min_timestamp = timestamps.min()\n",
    "\n",
    "# timestamp_buckets = np.linspace(\n",
    "#     min_timestamp, max_timestamp, num=1000,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define user and item models\n",
    "\n",
    "embedding_dimension = 32\n",
    "\n",
    "# Compute embeddings for users.\n",
    "user_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.StringLookup(\n",
    "    vocabulary=unique_user_ids, mask_token=None),\n",
    "    tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "])\n",
    "\n",
    "# Compute embeddings for movies.\n",
    "song_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.StringLookup(\n",
    "    vocabulary=unique_song_ids, mask_token=None),\n",
    "    tf.keras.layers.Embedding(len(unique_song_ids) + 1, embedding_dimension)\n",
    "])\n",
    "\n",
    "# timestamp model: concatenate with user_model!\n",
    "# timestamp_embedding = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Discretization(timestamp_buckets.tolist()),\n",
    "#     tf.keras.layers.Embedding(len(timestamp_buckets) + 1, 32),\n",
    "# ])\n",
    "# normalized_timestamp = tf.keras.layers.Normalization(\n",
    "#     axis=None\n",
    "# )\n",
    "\n",
    "# get top k recommendations\n",
    "metrics = tfrs.metrics.FactorizedTopK(\n",
    "  candidates=song_ids.map(song_model)\n",
    ")\n",
    "task = tfrs.tasks.Retrieval(\n",
    "  metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeezerRecModel(tfrs.Model):\n",
    "\n",
    "    def __init__(self, user_model, song_model):\n",
    "        super().__init__()\n",
    "        self.song_model = tf.keras.Model = song_model\n",
    "        self.user_model: tf.keras.Model = user_model\n",
    "\n",
    "        self.task: tf.keras.layers.Layer = task\n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        user_embeddings = self.user_model(features[\"user_id\"])\n",
    "        positive_song_embeddings = self.song_model(features[\"media_id\"])\n",
    "        return self.task(user_embeddings, positive_song_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/Users/oliviergisiger/.local/share/virtualenvs/deezer_recommendation-BCCDOVtY/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/oliviergisiger/.local/share/virtualenvs/deezer_recommendation-BCCDOVtY/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/oliviergisiger/.local/share/virtualenvs/deezer_recommendation-BCCDOVtY/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/oliviergisiger/.local/share/virtualenvs/deezer_recommendation-BCCDOVtY/lib/python3.10/site-packages/tensorflow_recommenders/models/base.py\", line 76, in train_step\n        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n    File \"/Users/oliviergisiger/.local/share/virtualenvs/deezer_recommendation-BCCDOVtY/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1140, in apply_gradients\n        return super().apply_gradients(grads_and_vars, name=name)\n    File \"/Users/oliviergisiger/.local/share/virtualenvs/deezer_recommendation-BCCDOVtY/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 621, in apply_gradients\n        self.build(trainable_variables)\n    File \"/Users/oliviergisiger/.local/share/virtualenvs/deezer_recommendation-BCCDOVtY/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/adagrad.py\", line 102, in build\n        initial_value=initializer(shape=var.shape, dtype=var.dtype),\n    File \"/Users/oliviergisiger/.local/share/virtualenvs/deezer_recommendation-BCCDOVtY/lib/python3.10/site-packages/keras/initializers/initializers_v2.py\", line 265, in __call__\n        return tf.constant(self.value, dtype=_get_dtype(dtype), shape=shape)\n\n    TypeError: Cannot convert 0.1 to EagerTensor of dtype int32\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m cached_train \u001b[38;5;241m=\u001b[39m train\u001b[38;5;241m.\u001b[39mshuffle(\u001b[38;5;241m100_000\u001b[39m)\u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;241m8192\u001b[39m)\u001b[38;5;241m.\u001b[39mcache()\n\u001b[1;32m      4\u001b[0m cached_test \u001b[38;5;241m=\u001b[39m test\u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;241m4096\u001b[39m)\u001b[38;5;241m.\u001b[39mcache()\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcached_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/deezer_recommendation-BCCDOVtY/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/b0/_hhr9zlj5wdd5ftyj21pr9vw0000gn/T/__autograph_generated_file1vdpmosy.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/deezer_recommendation-BCCDOVtY/lib/python3.10/site-packages/tensorflow_recommenders/models/base.py:76\u001b[0m, in \u001b[0;36mModel.train_step\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     73\u001b[0m   total_loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m+\u001b[39m regularization_loss\n\u001b[1;32m     75\u001b[0m gradients \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(total_loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgradients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m metrics \u001b[38;5;241m=\u001b[39m {metric\u001b[38;5;241m.\u001b[39mname: metric\u001b[38;5;241m.\u001b[39mresult() \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics}\n\u001b[1;32m     79\u001b[0m metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m loss\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/Users/oliviergisiger/.local/share/virtualenvs/deezer_recommendation-BCCDOVtY/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/oliviergisiger/.local/share/virtualenvs/deezer_recommendation-BCCDOVtY/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/oliviergisiger/.local/share/virtualenvs/deezer_recommendation-BCCDOVtY/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/oliviergisiger/.local/share/virtualenvs/deezer_recommendation-BCCDOVtY/lib/python3.10/site-packages/tensorflow_recommenders/models/base.py\", line 76, in train_step\n        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n    File \"/Users/oliviergisiger/.local/share/virtualenvs/deezer_recommendation-BCCDOVtY/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1140, in apply_gradients\n        return super().apply_gradients(grads_and_vars, name=name)\n    File \"/Users/oliviergisiger/.local/share/virtualenvs/deezer_recommendation-BCCDOVtY/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 621, in apply_gradients\n        self.build(trainable_variables)\n    File \"/Users/oliviergisiger/.local/share/virtualenvs/deezer_recommendation-BCCDOVtY/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/adagrad.py\", line 102, in build\n        initial_value=initializer(shape=var.shape, dtype=var.dtype),\n    File \"/Users/oliviergisiger/.local/share/virtualenvs/deezer_recommendation-BCCDOVtY/lib/python3.10/site-packages/keras/initializers/initializers_v2.py\", line 265, in __call__\n        return tf.constant(self.value, dtype=_get_dtype(dtype), shape=shape)\n\n    TypeError: Cannot convert 0.1 to EagerTensor of dtype int32\n"
     ]
    }
   ],
   "source": [
    "model = DeezerRecModel(user_model, song_model)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()\n",
    "model.fit(cached_train, epochs=3, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 17:34:36.019191: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-12 17:34:36.511381: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-12 17:34:36.530529: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - factorized_top_k/top_1_categorical_accuracy: 5.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 5.0000e-04 - factorized_top_k/top_10_categorical_accuracy: 5.0000e-04 - factorized_top_k/top_50_categorical_accuracy: 0.3430 - factorized_top_k/top_100_categorical_accuracy: 0.3470 - loss: 15202.0205 - regularization_loss: 0.0000e+00 - total_loss: 15202.0205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k/top_1_categorical_accuracy': 0.0005000000237487257,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.0005000000237487257,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.0005000000237487257,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.34300002455711365,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 0.34700000286102295,\n",
       " 'loss': 15202.0205078125,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 15202.0205078125}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BruteForce' object has no attribute 'index_from_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m index \u001b[38;5;241m=\u001b[39m tfrs\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mfactorized_top_k\u001b[38;5;241m.\u001b[39mBruteForce(model\u001b[38;5;241m.\u001b[39muser_model)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_from_dataset\u001b[49m(\n\u001b[1;32m      3\u001b[0m   tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mzip((songs\u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;241m1000\u001b[39m), songs\u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;241m1000\u001b[39m)\u001b[38;5;241m.\u001b[39mmap(model\u001b[38;5;241m.\u001b[39msong_model)))\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      6\u001b[0m _, titles \u001b[38;5;241m=\u001b[39m index(tf\u001b[38;5;241m.\u001b[39mconstant([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1387\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSong id Recommendations for user: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtitles[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;250m \u001b[39m:\u001b[38;5;241m3\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BruteForce' object has no attribute 'index_from_dataset'"
     ]
    }
   ],
   "source": [
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "index.index_from_dataset(\n",
    "  tf.data.Dataset.zip((songs.batch(1000), songs.batch(1000).map(model.song_model)))\n",
    ")\n",
    "\n",
    "_, titles = index(tf.constant([\"1387\"]))\n",
    "print(f\"Song id Recommendations for user: {titles[0, :3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrs.layers.factorized_top_k.BruteForce."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deezer_recommendation",
   "language": "python",
   "name": "deezer_recommendation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "7a25f741d35dae877df10624e2b896bc7b21e32390eb0ff94c7989a0b15a6df6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
