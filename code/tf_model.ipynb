{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Build\n",
    "\n",
    "<font color='red'>NOTE</font>\n",
    " \n",
    "* Notebook based on [this](https://www.tensorflow.org/recommenders/examples/basic_ranking) tutorial. \n",
    "* tf model not yet adapted for implicit rating, uses dense output layer atm; change to softmax. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from numpy import count_nonzero\n",
    "\n",
    "from typing import Dict, Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_item_matrix(df, show_head=False, get_info=True): \n",
    "    \"\"\"\n",
    "    Get the user-item frequency matrix, \n",
    "    and print infos about sparsity.\n",
    "    \"\"\"\n",
    "\n",
    "    st = time.time()\n",
    "    # get media x user table\n",
    "    tab = df.groupby(['media_id', 'user_id']).size()\n",
    "    # replace Nan\n",
    "    iu_mat = tab.unstack().fillna(0)\n",
    "    \n",
    "    if show_head:\n",
    "        print(iu_mat.head(5))\n",
    "    \n",
    "    # convert to nparray & compute sparsity\n",
    "    iu_mat = iu_mat.to_numpy()\n",
    "    sparsity = 1.0 - (count_nonzero(iu_mat) / float(iu_mat.size))\n",
    "    et = time.time()\n",
    "\n",
    "    if get_info:\n",
    "        print(f'\\n\\nNon-zero values: {count_nonzero(iu_mat)} \\nSize of matrix:',\n",
    "               f'{iu_mat.size}\\nMatrix sparsity: {sparsity}', \n",
    "               f'\\n\\nExecution time: {round((et-st)/60, 4)}min')\n",
    "    return iu_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/train.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/48/hls1bn594jv01b8czjn52sp80000gn/T/ipykernel_38414/643805895.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_small_df[['user_id', 'media_id']] = train_small_df[['user_id', 'media_id']].astype(str)\n"
     ]
    }
   ],
   "source": [
    "# get slice for processing speed\n",
    "train_small_df = train_df[:10000]\n",
    "\n",
    "# convert to string for lookup later\n",
    "train_small_df[['user_id', 'media_id']] = train_small_df[['user_id', 'media_id']].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre_id</th>\n",
       "      <th>ts_listen</th>\n",
       "      <th>media_id</th>\n",
       "      <th>album_id</th>\n",
       "      <th>context_type</th>\n",
       "      <th>release_date</th>\n",
       "      <th>platform_name</th>\n",
       "      <th>platform_family</th>\n",
       "      <th>media_duration</th>\n",
       "      <th>listen_type</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>user_id</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>user_age</th>\n",
       "      <th>is_listened</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25471</td>\n",
       "      <td>1480597215</td>\n",
       "      <td>222606</td>\n",
       "      <td>41774</td>\n",
       "      <td>12</td>\n",
       "      <td>20040704</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9241</td>\n",
       "      <td>55164</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25571</td>\n",
       "      <td>1480544735</td>\n",
       "      <td>250467</td>\n",
       "      <td>43941</td>\n",
       "      <td>0</td>\n",
       "      <td>20060301</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16547</td>\n",
       "      <td>55830</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>1479563953</td>\n",
       "      <td>305197</td>\n",
       "      <td>48078</td>\n",
       "      <td>1</td>\n",
       "      <td>20140714</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7665</td>\n",
       "      <td>2704</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>1480152098</td>\n",
       "      <td>900502</td>\n",
       "      <td>71521</td>\n",
       "      <td>0</td>\n",
       "      <td>20001030</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1580</td>\n",
       "      <td>938</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>1478368974</td>\n",
       "      <td>542335</td>\n",
       "      <td>71718</td>\n",
       "      <td>0</td>\n",
       "      <td>20080215</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1812</td>\n",
       "      <td>2939</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   genre_id   ts_listen media_id  album_id  context_type  release_date  \\\n",
       "0     25471  1480597215   222606     41774            12      20040704   \n",
       "1     25571  1480544735   250467     43941             0      20060301   \n",
       "2        16  1479563953   305197     48078             1      20140714   \n",
       "3         7  1480152098   900502     71521             0      20001030   \n",
       "4         7  1478368974   542335     71718             0      20080215   \n",
       "\n",
       "   platform_name  platform_family  media_duration  listen_type  user_gender  \\\n",
       "0              1                0             223            0            0   \n",
       "1              2                1             171            0            0   \n",
       "2              2                1             149            1            1   \n",
       "3              0                0             240            0            1   \n",
       "4              0                0             150            0            1   \n",
       "\n",
       "  user_id  artist_id  user_age  is_listened  \n",
       "0    9241      55164        29            0  \n",
       "1   16547      55830        30            1  \n",
       "2    7665       2704        29            1  \n",
       "3    1580        938        30            0  \n",
       "4    1812       2939        24            1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_small_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id     1   10  100  1000  10000  1001  10014  10015  10026  10027  ...  \\\n",
      "media_id                                                                ...   \n",
      "10093142  0.0  0.0  0.0   0.0    0.0   0.0    0.0    0.0    0.0    0.0  ...   \n",
      "10093143  0.0  0.0  0.0   0.0    0.0   0.0    0.0    0.0    0.0    0.0  ...   \n",
      "10093144  0.0  0.0  0.0   0.0    0.0   0.0    0.0    0.0    0.0    0.0  ...   \n",
      "10093145  0.0  0.0  0.0   0.0    0.0   0.0    0.0    0.0    0.0    0.0  ...   \n",
      "10093147  0.0  0.0  0.0   0.0    0.0   0.0    0.0    0.0    0.0    0.0  ...   \n",
      "\n",
      "user_id   9927  993  994  996  9965  9967  9975  998  999  9991  \n",
      "media_id                                                         \n",
      "10093142   0.0  0.0  0.0  0.0   0.0   0.0   0.0  0.0  0.0   0.0  \n",
      "10093143   0.0  0.0  0.0  0.0   0.0   0.0   0.0  0.0  0.0   0.0  \n",
      "10093144   0.0  0.0  0.0  0.0   0.0   0.0   0.0  0.0  0.0   0.0  \n",
      "10093145   0.0  0.0  0.0  0.0   0.0   0.0   0.0  0.0  0.0   0.0  \n",
      "10093147   0.0  0.0  0.0  0.0   0.0   0.0   0.0  0.0  0.0   0.0  \n",
      "\n",
      "[5 rows x 3231 columns]\n",
      "\n",
      "\n",
      "Non-zero values: 6029 \n",
      "Size of matrix: 2833587\n",
      "Matrix sparsity: 0.9978723081380596 \n",
      "\n",
      "Execution time: 0.0005min\n"
     ]
    }
   ],
   "source": [
    "#Â lookup user-item matrix:\n",
    "small_iu = get_user_item_matrix(train_small_df, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_id': b'9241', 'is_listened': 0, 'media_id': b'222606'}\n",
      "{'user_id': b'16547', 'is_listened': 1, 'media_id': b'250467'}\n",
      "{'user_id': b'7665', 'is_listened': 1, 'media_id': b'305197'}\n",
      "{'user_id': b'1580', 'is_listened': 0, 'media_id': b'900502'}\n",
      "{'user_id': b'1812', 'is_listened': 1, 'media_id': b'542335'}\n",
      "<MapDataset element_spec={'user_id': TensorSpec(shape=(), dtype=tf.string, name=None), 'is_listened': TensorSpec(shape=(), dtype=tf.int64, name=None), 'media_id': TensorSpec(shape=(), dtype=tf.string, name=None)}>\n"
     ]
    }
   ],
   "source": [
    "# convert to tfds datset\n",
    "\n",
    "deezer_ratings = tf.data.Dataset.from_tensor_slices(dict(train_small_df)).\\\n",
    "    map(lambda x: {\n",
    "    'user_id': x['user_id'], \n",
    "    'is_listened': x['is_listened'], \n",
    "    'media_id': x['media_id']})\n",
    "\n",
    "# get sample for overview\n",
    "for x in deezer_ratings.take(5).as_numpy_iterator():\n",
    "  print(x)\n",
    "\n",
    "# assert correct object type\n",
    "print(deezer_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = deezer_ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_ids = deezer_ratings.batch(1_000_000).map(lambda x: x[\"media_id\"])\n",
    "user_ids = deezer_ratings.batch(1_000_000).map(lambda x: x[\"user_id\"])\n",
    "\n",
    "unique_song_ids = np.unique(np.concatenate(list(song_ids)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankingModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    embedding_dimension = 32\n",
    "\n",
    "    # Compute embeddings for users.\n",
    "    self.user_embeddings = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_user_ids, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    # Compute embeddings for movies.\n",
    "    self.song_embeddings = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_song_ids, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_song_ids) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    # Compute predictions.\n",
    "    self.ratings = tf.keras.Sequential([\n",
    "      # Learn multiple dense layers.\n",
    "      tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "      tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "      # Make rating predictions in the final layer.\n",
    "      tf.keras.layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  def call(self, inputs):\n",
    "\n",
    "    user_id, song_ids = inputs\n",
    "\n",
    "    user_embedding = self.user_embeddings(user_id)\n",
    "    song_embedding = self.song_embeddings(song_ids)\n",
    "\n",
    "    return self.ratings(tf.concat([user_embedding, song_embedding], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of prediction return of model\n",
    "tf.print(RankingModel()(([\"100\"], [\"222606\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = tfrs.tasks.Ranking(\n",
    "  loss = tf.keras.losses.MeanSquaredError(),\n",
    "  metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeezerModel(tfrs.models.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.ranking_model: tf.keras.Model = RankingModel()\n",
    "    self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "      loss = tf.keras.losses.MeanSquaredError(),\n",
    "      metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "\n",
    "  def call(self, features: Dict[str, tf.Tensor]) -> tf.Tensor:\n",
    "    return self.ranking_model(\n",
    "        (features[\"user_id\"], features[\"media_id\"]))\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "    labels = features.pop(\"is_listened\")\n",
    "\n",
    "    rating_predictions = self(features)\n",
    "\n",
    "    # The task computes the loss and the metrics.\n",
    "    return self.task(labels=labels, predictions=rating_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeezerModel()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 8ms/step - root_mean_squared_error: 0.7757 - loss: 0.4301 - regularization_loss: 0.0000e+00 - total_loss: 0.4301\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 6ms/step - root_mean_squared_error: 0.4719 - loss: 0.2203 - regularization_loss: 0.0000e+00 - total_loss: 0.2203\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 8ms/step - root_mean_squared_error: 0.4710 - loss: 0.2197 - regularization_loss: 0.0000e+00 - total_loss: 0.2197\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 8ms/step - root_mean_squared_error: 0.4708 - loss: 0.2195 - regularization_loss: 0.0000e+00 - total_loss: 0.2195\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 5ms/step - root_mean_squared_error: 0.4707 - loss: 0.2194 - regularization_loss: 0.0000e+00 - total_loss: 0.2194\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 7ms/step - root_mean_squared_error: 0.4706 - loss: 0.2192 - regularization_loss: 0.0000e+00 - total_loss: 0.2192\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 6ms/step - root_mean_squared_error: 0.4704 - loss: 0.2191 - regularization_loss: 0.0000e+00 - total_loss: 0.2191\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 6ms/step - root_mean_squared_error: 0.4703 - loss: 0.2189 - regularization_loss: 0.0000e+00 - total_loss: 0.2189\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 8ms/step - root_mean_squared_error: 0.4702 - loss: 0.2188 - regularization_loss: 0.0000e+00 - total_loss: 0.2188\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 7ms/step - root_mean_squared_error: 0.4701 - loss: 0.2186 - regularization_loss: 0.0000e+00 - total_loss: 0.2186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a4175330>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()\n",
    "\n",
    "model.fit(cached_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(cached_test, return_dict=True)# does not work yet; float inf values because of 0's in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratings = {}\n",
    "test_movie_titles = [\"M*A*S*H (1970)\", \"Dances with Wolves (1990)\", \"Speed (1994)\"]\n",
    "for movie_title in test_movie_titles:\n",
    "  test_ratings[movie_title] = model({\n",
    "      \"user_id\": np.array([\"42\"]),\n",
    "      \"movie_title\": np.array([movie_title])\n",
    "  })\n",
    "\n",
    "print(\"Ratings:\")\n",
    "for title, score in sorted(test_ratings.items(), key=lambda x: x[1], reverse=True):\n",
    "  print(f\"{title}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.saved_model.save(model, \"export\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deezer_recommendation-LXH-S8nB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a25f741d35dae877df10624e2b896bc7b21e32390eb0ff94c7989a0b15a6df6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
